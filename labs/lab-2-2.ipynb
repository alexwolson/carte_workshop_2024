{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMcD6m6l8Ut8vEnqam8Fx4F"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f6d84beb6f8e477a9c0d45817accc8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3996aef1fc0f4b7ea9a5f6dbaffd4fba",
       "IPY_MODEL_330269805d30447895208d5c4f79e728",
       "IPY_MODEL_adee0055ed694b0a9f643a489d3fb08a"
      ],
      "layout": "IPY_MODEL_76b654fd1e0a4da8b4a3bb949c286086"
     }
    },
    "3996aef1fc0f4b7ea9a5f6dbaffd4fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e05c7217178646a1b362f13e93d7fc00",
      "placeholder": "​",
      "style": "IPY_MODEL_6f35d1788d3b498ca7dccc8072a36daf",
      "value": "Best trial: 95. Best value: 0.817528: 100%"
     }
    },
    "330269805d30447895208d5c4f79e728": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d85108019624c6bb12a020175c24afe",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cd81b6de72048c8961aa7778b653a0b",
      "value": 100
     }
    },
    "adee0055ed694b0a9f643a489d3fb08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a08383cb3b24b129429c401fa4e8df4",
      "placeholder": "​",
      "style": "IPY_MODEL_1b58e8e784a045e08d6605205d63150a",
      "value": " 100/100 [02:04&lt;00:00,  1.24s/it]"
     }
    },
    "76b654fd1e0a4da8b4a3bb949c286086": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e05c7217178646a1b362f13e93d7fc00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f35d1788d3b498ca7dccc8072a36daf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d85108019624c6bb12a020175c24afe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cd81b6de72048c8961aa7778b653a0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a08383cb3b24b129429c401fa4e8df4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b58e8e784a045e08d6605205d63150a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0aef6ccaf6d43e1b5c400b2307a265e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f21470133c574f5c9d0707c979038cbf",
       "IPY_MODEL_ecf72f14216949e3b93f5f0f78f9baba",
       "IPY_MODEL_6e6a13c6cb6640d2b874207cb29d487e"
      ],
      "layout": "IPY_MODEL_7ea0dc58b97e422283f5822274fa68df"
     }
    },
    "f21470133c574f5c9d0707c979038cbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41c5428891fb4b9e8e00545c027a4794",
      "placeholder": "​",
      "style": "IPY_MODEL_171232bb06a841698fd3af2bef742cb7",
      "value": "Best trial: 86. Best value: 0.79509: 100%"
     }
    },
    "ecf72f14216949e3b93f5f0f78f9baba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf6ad7ae768647b6b317ca2266c9f784",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02f8ea4fe50c495cb38378ca1e16dc6b",
      "value": 100
     }
    },
    "6e6a13c6cb6640d2b874207cb29d487e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c2094a8784c452dbf4bed4c449e1471",
      "placeholder": "​",
      "style": "IPY_MODEL_6a85def097714d12943770ae703d7000",
      "value": " 100/100 [21:26&lt;00:00, 15.40s/it]"
     }
    },
    "7ea0dc58b97e422283f5822274fa68df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41c5428891fb4b9e8e00545c027a4794": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "171232bb06a841698fd3af2bef742cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf6ad7ae768647b6b317ca2266c9f784": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02f8ea4fe50c495cb38378ca1e16dc6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c2094a8784c452dbf4bed4c449e1471": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a85def097714d12943770ae703d7000": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alexwolson/postdocbootcamp2023/blob/main/lab_1_2_hyperparameters.ipynb)\n",
    "\n",
    "# UofT DSI-CARTE Postdoc Bootcamp\n",
    "#### Tuesday, July 18, 2023\n",
    "#### Hyperparameter Tuning - Lab 2, Day 1\n",
    "#### Teaching team: Alex Olson, Nakul Upadhya, Shehnaz Islam\n",
    "##### Lab author: Nakul Upadhya (referencing work by Kyle E. C. Booth and Jake Mosseri), edited by Alex Olson"
   ],
   "metadata": {
    "id": "ACsD78d8vjSa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Machine Learning operates by solving an optimization problem to determine the parameters of a function that best fits the data. However, some parameters - known as hyperparameters - can't be learned through this process, as they set the model structure and guide the optimization procedure. Tuning these hyperparameters is a crucial part of model development and can greatly impact model performance.\n",
    "\n",
    "Hyperparameter tuning refers to the task of discovering the optimal hyperparameters for a given model and dataset. This process is a key stage in the machine learning workflow. Nevertheless, it poses a challenging task due to its complex nature - there is no universal methodology that applies to all scenarios. The selection of the best hyperparameters relies heavily on the dataset at hand, the chosen model architecture, and the specific learning task. Therefore, identifying the ideal set of hyperparameters is not about finding a one-size-fits-all solution, but rather about employing a mix of intuition, systematic testing, and optimization techniques.\n",
    "\n",
    "In this lab, we will delve into the fundamentals of hyperparameter tuning, exploring methods such as Grid Search, Cross Validation, and Bayesian Optimization. Let's dive in!"
   ],
   "metadata": {
    "id": "HIPYMpobxpaD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test whether we are running in Google Colab\n",
    "IN_COLAB = \"google.colab\" in str(get_ipython())\n",
    "print(\"Running in Colab: \", IN_COLAB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    # Colab already has these installed\n",
    "    !pip install -q torch torchvision torchaudio numpy pandas matplotlib scikit-learn\n",
    "!pip install -q optuna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import standard libraries\n",
    "import numpy as np"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHB2yx2Gxpop",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689198423116,
     "user_tz": 240,
     "elapsed": 65609,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "36494fc7-062f-494e-b062-2c7c91e865ea"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this lab, we'll be using the Titanic dataset. To prepare our dataset for the subsequent learning tasks, we'll have to perform the following steps:\n",
    "\n",
    "1. Discard irrelevant columns: Some columns may not contribute to the model's predictive performance and can be removed.\n",
    "2. Adjust data types of certain columns: Some columns may have incorrect data types that need to be fixed for proper analysis.\n",
    "3. Split the dataset into Training and Test sets: This ensures we have a separate dataset (Test set) to evaluate our model's performance.\n",
    "4. Handle missing values: We need to impute or fill in missing values to avoid complications during the learning process.\n",
    "5. Scale the data: It's necessary to standardize our data to ensure all features have equal importance in model training.\n",
    "\n",
    "We'll be carrying out all these steps in the following cells:"
   ],
   "metadata": {
    "id": "28XanXRqznHx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import libraries for data handling and manipulation\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch data\n",
    "data = fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"auto\").frame\n",
    "\n",
    "# Select features\n",
    "unimportant_cols = [\"name\", \"ticket\", \"cabin\", \"embarked\", \"boat\", \"body\", \"home.dest\"]\n",
    "data = data.drop(unimportant_cols, axis=1)\n",
    "\n",
    "# Encode categorical features and convert relevant columns to numeric data type\n",
    "le = LabelEncoder()\n",
    "data[\"sex\"] = le.fit_transform(data[\"sex\"])\n",
    "data[\"survived\"] = data[\"survived\"].astype(\"int\")\n",
    "\n",
    "# Split data into features and target\n",
    "target_data = data[\"survived\"]\n",
    "feature_data = data.drop(\"survived\", axis=1)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_data, target_data, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Handle missing values with imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Print information about the final dataset\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} training data points and {X_test.shape[0]} testing points\"\n",
    ")\n",
    "print(f\"There are {X_train.shape[1]} features in the dataset\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUNddJ_Ez2gU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689198424388,
     "user_tz": 240,
     "elapsed": 1275,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "09e0c562-fe79-47c1-bc41-d88caac6df82"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Search\n",
    "\n",
    "With our data ready, we can commence our exploration of hyperparameter tuning. Our initial approach will be grid search, a method that involves constructing a grid of potential hyperparameters and systematically examining the model's performance for each combination. To attain a reliable measure of model performance, grid search is often combined with K-Fold cross-validation. The Grid Search CV process involves:\n",
    "\n",
    "1. Hyperparameter grid definition: Identify the hyperparameters to be tuned and designate possible values for each one. This forms a grid, where each point represents a unique set of hyperparameters.\n",
    "2. Cross-validation across folds: For each unique set of hyperparameters, execute a K-Fold Cross-validation on your model and calculate the average error.\n",
    "3. Hyperparameters selection: Opt for the hyperparameters that result in the best performance (i.e., the lowest error).\n",
    "\n",
    "Let's delve into the impact of hyperparameter tuning using a simple Random Forest Classifier in the following section."
   ],
   "metadata": {
    "id": "N5VIfGvg5CJr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import required libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from time import time\n",
    "\n",
    "print(\"Setting up a Random Forest Classifier...\")\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "print(\"Defining hyperparameters for Grid Search...\")\n",
    "hyperparameter_search = {\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],  # Max Depth of each individual tree\n",
    "    \"n_estimators\": [50, 100, 150, 200],  # Number of trees generated\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],  # Minimum number of samples found in a leaf\n",
    "    \"min_samples_split\": [2, 4, 8, 16, 32],  # Minimum samples required for a split\n",
    "}\n",
    "\n",
    "print(\"Setting up Grid Search with 5-fold Cross Validation...\")\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=hyperparameter_search,\n",
    "    scoring=make_scorer(accuracy_score, greater_is_better=True),\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "print(\"Running Grid Search (This may take a while)...\")\n",
    "start_time = time()\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "\n",
    "print(f\"Grid Search completed in {end_time - start_time:.0f} seconds\")\n",
    "\n",
    "print(f\"Best Parameters: {grid_search_cv.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_search_cv.best_score_ * 100:.2f}%\")\n",
    "\n",
    "print(\"Evaluating model on test data...\")\n",
    "clf = grid_search_cv.best_estimator_\n",
    "test_predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-t1k64t-O2U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689198943839,
     "user_tz": 240,
     "elapsed": 519453,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "419c2834-552c-4489-b74b-807b112d8719"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Parameter Searching\n",
    "\n",
    "While Grid Search proves effective in many scenarios, its major limitation is its computational demand. The number of models to be trained escalates exponentially with each additional hyperparameter. In our previous example, we had to train a model over five thousand times due to the 1024 combinations ($4^5$) and 5-fold cross-validation. This approach might be feasible for simpler models like Random Forests or Linear/Logistic regression, but it becomes prohibitively time-consuming for deep learning models or when dealing with a large search space.\n",
    "\n",
    "## Introducing Bayesian Optimization\n",
    "\n",
    "An alternative hyperparameter tuning technique, Bayesian Optimization, can help mitigate these computational concerns. It's a sequential, model-based optimization method used to find the optimal hyperparameters for a given machine learning model. This technique combines Bayesian inference and optimization to identify promising regions for evaluation, utilizing a surrogate model to approximate the performance of our primary model concerning its hyperparameters.\n",
    "\n",
    "One of the key advantages of Bayesian optimization is its efficient exploration of the hyperparameter space, which provides a significant edge over exhaustive search methods like grid search. It intelligently selects new configurations based on predictions from the surrogate model, thus converging to the optimal hyperparameters more rapidly and with fewer evaluations.\n",
    "\n",
    "Next, let's apply Bayesian Optimization for parameter search in our Random Forest model. We'll leverage Optuna, a hyperparameter optimization library that encapsulates this approach."
   ],
   "metadata": {
    "id": "iznvVdvCA7vj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    # Print the trial number, the best value and parameters after each trial\n",
    "    print(f\"\\nTrial {trial.number} finished.\")\n",
    "    print(f\"Best value after trial {trial.number}: {study.best_value:.3f}\")\n",
    "    print(f\"Best params after trial {trial.number}: {study.best_params}\")\n",
    "\n",
    "\n",
    "# Define a function that specifies the model, the search space and trains the model\n",
    "# Optuna will try to optimize the hyperparameters to maximize the output of this function\n",
    "def optuna_rf_function(trial):\n",
    "    hyperparameters = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 8),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**hyperparameters)\n",
    "\n",
    "    # Evaluate the model using cross-validation and calculate the mean test score\n",
    "    cv_result = cross_validate(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    return cv_result[\"test_score\"].mean()\n",
    "\n",
    "\n",
    "# Create an Optuna study object\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize the study using the sampler\n",
    "study.optimize(\n",
    "    optuna_rf_function,\n",
    "    n_trials=100,\n",
    "    callbacks=[print_callback],\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f6d84beb6f8e477a9c0d45817accc8b0",
      "3996aef1fc0f4b7ea9a5f6dbaffd4fba",
      "330269805d30447895208d5c4f79e728",
      "adee0055ed694b0a9f643a489d3fb08a",
      "76b654fd1e0a4da8b4a3bb949c286086",
      "e05c7217178646a1b362f13e93d7fc00",
      "6f35d1788d3b498ca7dccc8072a36daf",
      "2d85108019624c6bb12a020175c24afe",
      "0cd81b6de72048c8961aa7778b653a0b",
      "9a08383cb3b24b129429c401fa4e8df4",
      "1b58e8e784a045e08d6605205d63150a"
     ]
    },
    "id": "nEDytL6uA4oU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689199069057,
     "user_tz": 240,
     "elapsed": 125228,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "8625709b-04be-468e-f957-c84f3972c85d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def print_accuracy(accuracy, dataset_name):\n",
    "    print(f\"{dataset_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Obtain the best parameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "# Display the best parameters and their corresponding accuracy\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print_accuracy(best_accuracy, \"Best CV\")\n",
    "\n",
    "# Train the best model on the training data\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and calculate the accuracy\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the test accuracy\n",
    "print_accuracy(test_accuracy, \"Testing\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6RsdF9nJCkF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689199069230,
     "user_tz": 240,
     "elapsed": 183,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "85f309ba-77a8-4720-991c-7d1dbf2ddf84"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your Turn**\n",
    "\n",
    "- How do the CV accuracies of the grid search and Optuna compare? ______________\n",
    "- What differences do you notice in their testing accuracies? ______________\n",
    "- Which method completed faster, and why do you think this was the case? ______________\n",
    "\n",
    "Hyperparameter Tuning for Neural Networks\n",
    "\n",
    "One compelling use case for Bayesian Optimization is hyperparameter tuning for neural networks. Training these models can be time-consuming and their performance can be significantly affected by hyperparameters such as dropout rate, learning rate, weight decay, batch size, among others. Let's explore how we can optimize these parameters for a neural network.\n",
    "Constructing Our Network\n",
    "\n",
    "We'll create a straightforward neural network punctuated by ReLU non-linearities. To streamline the hyperparameter search process, we'll encapsulate our training and prediction logic within this class.\n",
    "\n",
    "Our hyperparameters for this network will include:\n",
    "\n",
    "- The batch size utilized during training\n",
    "- The learning rate for the training process\n",
    "- The number of training epochs\n",
    "- The size of the hidden layer in the network."
   ],
   "metadata": {
    "id": "KfQzBH9VKUyU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "class TitanicMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple two-layer network for the Titanic dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, learning_rate, epochs):\n",
    "        super(TitanicMLP, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Define the forward pass layers\n",
    "        self.forward_pass = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform the forward pass.\n",
    "        \"\"\"\n",
    "        return self.forward_pass(x)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "\n",
    "        # Create tensors\n",
    "        X_tensor = torch.Tensor(X).float()\n",
    "        Y_tensor = torch.Tensor(y).float()\n",
    "\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_idx, (features, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()  # reset gradients\n",
    "                outputs = self.forward(features)  # forward pass\n",
    "                loss = self.criterion(\n",
    "                    torch.squeeze(outputs), torch.squeeze(target)\n",
    "                )  # calculate loss\n",
    "                loss.backward()  # backpropagation\n",
    "                self.optimizer.step()  # update weights\n",
    "\n",
    "            # Print progress\n",
    "            if (epoch + 1) % 10 == 0 and epoch != 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class of the input data X.\n",
    "        \"\"\"\n",
    "        self.eval()  # switch to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.Tensor(X)\n",
    "            y_pred = torch.sigmoid(\n",
    "                self.forward(X_tensor)\n",
    "            )  # apply sigmoid for binary output\n",
    "            y_pred = (\n",
    "                torch.round(y_pred).squeeze().numpy()\n",
    "            )  # round to nearest integer (0 or 1) and convert to numpy array\n",
    "        return y_pred"
   ],
   "metadata": {
    "id": "ckZ8n0ZOKTbF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, it's time to configure Optuna. Thanks to our network class having fit and predict functions, we can actually reuse much of our code from the Random Forest example.\n",
    "\n",
    "**Your Turn**\n",
    "\n",
    "- Currently, the Hyperparameter search has some placeholder values passed in. Replace these fixed values with Optuna variables to search the space.\n",
    "- Examine the scores produced for the various parameter configurations tested by Optuna. Do they exhibit similar performance, or do they significantly influence the model's effectiveness?\n",
    "\n",
    "Remember, the purpose of hyperparameter tuning is to optimize the model's performance, and sometimes even a minor change in parameters can lead to substantial improvement. So, it's crucial to pay close attention to the scores and make adjustments as necessary."
   ],
   "metadata": {
    "id": "pLPKZ119ZUHn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def optuna_mlp_function(trial):\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        \"input_dim\": trial.suggest_categorical(\n",
    "            \"input_dim\", [X_train.shape[1]]\n",
    "        ),  # Fixed parameter, no need to include in the trial\n",
    "        \"hidden_dim\": 1,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = TitanicMLP(**hyperparameters)\n",
    "    scores = []\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, val_index in kfold.split(X_train, y_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train.values[train_index]\n",
    "        X_val_fold = X_train[val_index]\n",
    "        y_val_fold = y_train.values[val_index]\n",
    "\n",
    "        # Fit the model and predict on the validation data\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Append the accuracy score to the list of scores\n",
    "        scores.append(accuracy_score(y_val_fold, y_pred))\n",
    "\n",
    "    # Return the mean cross-validation accuracy\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Initialize the Optuna study and set the optimization direction\n",
    "mlp_study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Run the optimization\n",
    "mlp_study.optimize(\n",
    "    optuna_mlp_function,\n",
    "    n_trials=100,\n",
    "    callbacks=[print_callback],\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e0aef6ccaf6d43e1b5c400b2307a265e",
      "f21470133c574f5c9d0707c979038cbf",
      "ecf72f14216949e3b93f5f0f78f9baba",
      "6e6a13c6cb6640d2b874207cb29d487e",
      "7ea0dc58b97e422283f5822274fa68df",
      "41c5428891fb4b9e8e00545c027a4794",
      "171232bb06a841698fd3af2bef742cb7",
      "cf6ad7ae768647b6b317ca2266c9f784",
      "02f8ea4fe50c495cb38378ca1e16dc6b",
      "7c2094a8784c452dbf4bed4c449e1471",
      "6a85def097714d12943770ae703d7000"
     ]
    },
    "id": "JNAl8udWXi8v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689200358759,
     "user_tz": 240,
     "elapsed": 1286587,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "d139da5c-1812-460a-a91a-9d38284391d5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_params = mlp_study.best_params\n",
    "best_accuracy = mlp_study.best_value\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print_accuracy(best_accuracy, \"Best CV\")\n",
    "\n",
    "best_model = TitanicMLP(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print_accuracy(test_accuracy, \"Testing\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU5CsRnAa4N9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689200362022,
     "user_tz": 240,
     "elapsed": 3265,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "34f5c470-8cb0-4152-93c1-a5b6277475a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your Turn**\n",
    "\n",
    "Besides the parameters we searched for above, can you think of other hyperparameters that could be tuned in a Neural Network?\n",
    "\n",
    "Hint: There are several aspects of a Neural Network's architecture and training process that can be adjusted. These could include the type of optimizer used, the activation functions applied, the initialization method for weights, and much more. Think about the various components that make up a Neural Network and how adjusting them might impact the model's performance."
   ],
   "metadata": {
    "id": "in1P8TDhF8jV"
   }
  }
 ]
}
