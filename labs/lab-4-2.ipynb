{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gene2Vec\n",
    "\n",
    "Gene2Vec is a method to learn gene embeddings from gene expression data. The method is based on the Word2Vec model, which is a popular method to learn word embeddings from text data. The idea is to learn a low-dimensional representation of genes that captures the relationships between genes based on their expression profiles. The gene embeddings can then be used for various downstream tasks, such as gene function prediction, gene expression analysis, and gene network analysis.\n",
    "\n",
    "Gene2Vec was trained to produce 200-dimensional vectors for all human genes, using co-expression data obtained from 984 datasets. We can load it below:"
   ],
   "id": "faafb5f9e6ad9da7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "gene2vec_url = 'https://raw.githubusercontent.com/jingcheng-du/Gene2vec/master/pre_trained_emb/gene2vec_dim_200_iter_9_w2v.txt'",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Loading Gene2Vec\n",
    "\n",
    "We can load the Gene2Vec model using the Gensim library. Gensim is a popular library for working with word embeddings, and it provides an easy-to-use interface for loading and working with pre-trained word embeddings. Let's load the Gene2Vec model and explore the embeddings:"
   ],
   "id": "987d68e98aef7612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -U -q gensim",
   "id": "b6998331cd28eb36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "gene2vec = KeyedVectors.load_word2vec_format(gene2vec_url)"
   ],
   "id": "e491d4e3dac09d46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now the word embeddings are loaded inside the `gene2vec` object. We can use this object to access the embeddings for individual genes and perform various operations, such as finding similar genes or performing vector arithmetic on gene embeddings. Let's explore some of these operations:\n",
    "\n",
    "Load the embeddings for a specific gene:"
   ],
   "id": "1117a1341bbcbd50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gene2vec['TP53']",
   "id": "dbdc152ce1fe2b09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find the most similar genes to a given gene:",
   "id": "56d778719aa1bf7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gene2vec.most_similar('TP53')",
   "id": "15b2dc07a0d67a0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find the most similar genes to a combination of genes - this is a bit more complex, but you can think of this operation as finding genes that are similar to the combination of the two genes and different from the third gene:",
   "id": "35a3527eb0fda8f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gene2vec.most_similar(positive=['TP53', 'BRCA1'], negative=['BRCA2'])",
   "id": "dd7c62760919d771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also apply dimensionality reduction to visualize the genes. For this, we'll use the Plotly library, because it'll allow us to mouse over the points and see the gene names. Let's visualize the gene embeddings using UMAP:",
   "id": "a62065f404a189f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -U -q umap-learn plotly",
   "id": "76dd28ae4d7c8f3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import umap\n",
    "\n",
    "embedding = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine').fit_transform(gene2vec.vectors)"
   ],
   "id": "d62c4e66986ad5ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(x=embedding[:, 0], y=embedding[:, 1], text=gene2vec.index_to_key)\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title='Gene2Vec Embeddings')\n",
    "fig.show()"
   ],
   "id": "e68ce5e156daf39d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Augmenting data using embeddings\n",
    "\n",
    "We can take advantage of these embeddings to augment performance in an existing task. Let's see how introducing these embeddings can improve our results on the HCC data:"
   ],
   "id": "fb2a06997b2adca0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "hcc = pd.read_csv('https://github.com/alexwolson/carte_workshop_2024/raw/main/data/HCC_all_ML_classification_test_annotated_frags_all_features_combined_4_tumors.csv.gz', compression='gzip')"
   ],
   "id": "507bae02b08c7518",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vocab = set(gene2vec.index_to_key)",
   "id": "39ab8196769fe1e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hcc = hcc[hcc.gene.isin(vocab)]",
   "id": "2dab472a2bb83348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hcc = hcc.sample(2000)",
   "id": "20d6c1ae1f70e73a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical_columns = ['chr','upstream_motif','downstream_motif','Corrected_Call']\n",
    "numerical_columns = ['frag','VAF','pos','read_cov','detected_read_cov','plasma_VAF','Corrected_Copy_Number']\n",
    "y_column = 'alt_match'\n",
    "\n",
    "X = hcc[categorical_columns + numerical_columns]\n",
    "y = hcc[y_column]"
   ],
   "id": "ecf721433dd208b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X = pd.get_dummies(X, columns=categorical_columns)",
   "id": "94aaa2496ea65e5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X = X.values",
   "id": "217f1eb99be6982b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "gene_embeddings = hcc.gene.map(gene2vec.get_vector).values\n",
    "gene_embeddings = np.stack(gene_embeddings)\n",
    "\n",
    "print(gene_embeddings.shape)"
   ],
   "id": "ba2d1aaa83a8d316",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X = np.concatenate([X, gene_embeddings], axis=1)",
   "id": "9267cc3ed7c3eb62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X.shape)",
   "id": "7dc12d6f6480ea48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "fca8c2d746cc76a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training a model\n",
    "\n",
    "Now, train a model on the augmented data. You can import any model you'd like, such as a Random Forest or Gradient Boosting Machine."
   ],
   "id": "c2977a0b43ff8ee6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "72cbaab79cca2102",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
